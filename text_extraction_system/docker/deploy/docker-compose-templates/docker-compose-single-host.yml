version: "3.8"
services:
  # Service names should comply with the rules of building DNS names - they will be available
  # under these domain names inside the cluster virtual network.
  # (Service names should not contain underscores.)

  ${DOCKER_WEBDAV_HOSTNAME}:
    image: ${DOCKER_WEBDAV_IMAGE}
    networks:
      ${TEXT_EXTRACTION_SWARM_NETWORK}:
    volumes:
      - file_storage:/var/lib/dav
    environment:   # No need for auth - in prod envs the server is not accessible from outside of our network
      AUTH_TYPE: Basic
      USERNAME: ${DOCKER_WEBDAV_AUTH_USER}
      PASSWORD: ${DOCKER_WEBDAV_AUTH_PASSWORD}
    sysctls:
      net.ipv4.vs.conn_reuse_mode: 0
      net.ipv4.vs.expire_nodest_conn: 1
      net.ipv4.tcp_keepalive_time: 600
      net.ipv4.tcp_keepalive_intvl: 60
      net.ipv4.tcp_keepalive_probes: 3
    logging:
      driver: "json-file"
      options:
        max-file: 5
        max-size: 10m
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
    ports:
      - mode: host
        protocol: tcp
        published: ${DOCKER_WEBDAV_PORT}
        target: 80

  ${DOCKER_REDIS_HOST_NAME}:
    image: ${DOCKER_REDIS_IMAGE}
    networks:
      ${TEXT_EXTRACTION_SWARM_NETWORK}:
    sysctls:
      net.ipv4.vs.conn_reuse_mode: 0
      net.ipv4.vs.expire_nodest_conn: 1
      net.ipv4.tcp_keepalive_time: 600
      net.ipv4.tcp_keepalive_intvl: 60
      net.ipv4.tcp_keepalive_probes: 3
    logging:
      driver: "json-file"
      options:
        max-file: 5
        max-size: 10m
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
    volumes:
      - redis_data:/data

  tes-celery:
    image: ${TEXT_EXTRACTION_SYSTEM_IMAGE}
    networks:
      ${TEXT_EXTRACTION_SWARM_NETWORK}:
    sysctls:
      net.ipv4.vs.conn_reuse_mode: 0
      net.ipv4.vs.expire_nodest_conn: 1
      net.ipv4.tcp_keepalive_time: 600
      net.ipv4.tcp_keepalive_intvl: 60
      net.ipv4.tcp_keepalive_probes: 3
    command: ["celery-worker"]
    environment:
      - "text_extraction_system_celery_broker=redis://tasks.${DOCKER_REDIS_HOST_NAME}:6379/0"
      - "text_extraction_system_celery_backend=redis://tasks.${DOCKER_REDIS_HOST_NAME}:6379/0"
      - "text_extraction_system_webdav_url=http://tasks.${DOCKER_WEBDAV_HOSTNAME}:${DOCKER_WEBDAV_PORT}"
      - "text_extraction_system_webdav_username=${DOCKER_WEBDAV_AUTH_USER}"
      - "text_extraction_system_webdav_password=${DOCKER_WEBDAV_AUTH_PASSWORD}"
      - "text_extraction_system_delete_temp_files_on_request_finish=${TEXT_EXTRACTION_SYSTEM_DELETE_TEMP_FILES_ON_REQUEST_FINISHED}"
      - "text_extraction_system_keep_failed_files=${TEXT_EXTRACTION_SYSTEM_KEEP_FAILED_FILES}"
    volumes:
      - celery_worker_state:/data/celery_worker_state
    deploy:
      mode: global # Exactly one instance per node. Primitive AWS autoscaling solution.
    stop_signal: SIGQUIT
    stop_grace_period: 1m
    logging:
      driver: "json-file"
      options:
        max-file: 5
        max-size: 10m

  tes-web-api:
    image: ${TEXT_EXTRACTION_SYSTEM_IMAGE}
    networks:
      ${TEXT_EXTRACTION_SWARM_NETWORK}:
    sysctls:
      net.ipv4.vs.conn_reuse_mode: 0
      net.ipv4.vs.expire_nodest_conn: 1
      net.ipv4.tcp_keepalive_time: 600
      net.ipv4.tcp_keepalive_intvl: 60
      net.ipv4.tcp_keepalive_probes: 3
    command: ["web-api"]
    stop_signal: SIGTERM
    environment:
      - "text_extraction_system_celery_broker=redis://tasks.${DOCKER_REDIS_HOST_NAME}:6379/0"
      - "text_extraction_system_celery_backend=redis://tasks.${DOCKER_REDIS_HOST_NAME}:6379/0"
      - "text_extraction_system_webdav_url=http://tasks.${DOCKER_WEBDAV_HOSTNAME}:${DOCKER_WEBDAV_PORT}"
      - "text_extraction_system_webdav_username=${DOCKER_WEBDAV_AUTH_USER}"
      - "text_extraction_system_webdav_password=${DOCKER_WEBDAV_AUTH_PASSWORD}"
      - "text_extraction_system_delete_temp_files_on_request_finish=${TEXT_EXTRACTION_SYSTEM_DELETE_TEMP_FILES_ON_REQUEST_FINISHED}"
      - "text_extraction_system_keep_failed_files=${TEXT_EXTRACTION_SYSTEM_KEEP_FAILED_FILES}"
      - "text_extraction_system_root_path=${TEXT_EXTRACTION_SYSTEM_ROOT_PATH}"
    logging:
      driver: "json-file"
      options:
        max-file: 5
        max-size: 10m
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
    ports:
      - 8000:8000

volumes:
  file_storage:
  redis_data:
  celery_worker_state:

networks:
  ${TEXT_EXTRACTION_SWARM_NETWORK}:
    external: true
